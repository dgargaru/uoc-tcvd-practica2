---
title: "Práctica 2: Proyecto analítico. Integración, limpieza, validación y análisis"
author: "Alba Caderno Fernández - Diego García García"
date: "28 de diciembre de 2022"
output:
  html_document:
    highlight: default
    theme: cosmo
    toc: yes
    number_sections: yes
    anchor_sections: yes
    toc_float:
      collapsed: false
      smooth_scroll: false
encoding: "utf-8"
lang: es    
---
<style type="text/css">

h1.title {
  text-align: center;
}
</style>
```{css, echo=FALSE}
h4 {
  text-align: center;
}
```

# Índice {-}

# Detalles de la actividad   

## Descripción  
El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la Práctica 1 o bien cualquier dataset libre disponible en Kaggle https://www.kaggle.com.  

Un ejemplo de dataset con el que podéis trabajar es el “Heart Attack Analysis & Prediction dataset”: https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-predictiondataset 

<b>Importante:</b> si se elige un dataset diferente al propuesto es importante que este contenga una amplia variedad de datos numéricos y categóricos para poder realizar un
análisis más rico y poder responder a las diferentes preguntas planteadas en el enunciado de la práctica.

## Objetivos  
Los objetivos concretos de esta práctica son:
<ul>
<li>Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.</li>
<li>Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.</li>
</li>Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.</li>
<li>Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.</li>
<li>Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.</li>
<li>Desarrollar las habilidades de aprendizaje que les permitan continuarestudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.</li>
<li>Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.</li>
</ul>

## Competencias  
En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

<li>Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.</li>
<li>Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.</li>

# Resolución  

## Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?  
El Dataset escogido en el enunciado de la práctica 2 nos muestra los datos para la clasificación de ataques al corazón. Dentro del conjunto de datos nos encontramos con 14 atributos provenientes de 4 bases de datos distintas del Instituto Húngaro de Cardiología en Budapest por Andras Janosi, el Hospital Universitario, Zurich, en Suiza por William Steinbrunn, el Hospital Universitario, Basilea, en Suiza por Matthias Pfisterer y el V.A. Medical Center en Long Beach y Cleveland Clinic Foundation por Robert Detrano.   

El atributo objetivo(output) hace referencia a la presencia de enfermedad cardíaca en el paciente siendo su escala de valores de 0 a 4. Por tanto, a raíz de los valores del conjuntos de datos se quiere averiguar la influencia de las distintas variables con el fin de determinar la presencia (¿es propenso?) de enfermedad cadíaca en los pacientes de estudio.

<b>Nota:</b> Tener en cuenta que en el atributo thall para el valor 0 se ha rellenado el dato con el value null por lo que puede ser necesario usar alguna técnica de ML supervisada para asignarle un valor "aproximado".  

<ul>
<li><b>Age:</b> Edad del paciente en años.</li>
<li><b>Sex:</b> Sexo del paciente.</li>
  <ul>
    <li>Valor 1: masculino</li>
    <li>Valor 0: femenino</li>
  </ul>
<li><b>cp:</b> Tipo de dolor en el pecho.</li>
  <ul>
    <li>Valor 0: Asintomático</li>
    <li>Valor 1: Angina típica</li>
    <li>Valor 2: Angina atípica</li>
    <li>Valor 3: Dolor no-anginoso</li>
  </ul>
<li><b>trtbps:</b> Presión arterial en reposo medida en el servicio de admisión del hospital en mm Hg. La presión sistólica.</li>
<li><b>chol:</b> Colesterol en mg/dl obtenido a través del sensor BMI</li>
<li><b>fbs:</b> Glucemia en ayunas > 120 mg/dl.</li>
<ul>
 <li>Valor 1: Verdadero</li>
 <li>Valor 0: Falso</li>
</ul>
<li><b>rest_ecg:</b> Resultados electrocardiográficos en reposo</li>
  <ul>
    <li>Valor 0: Normal</li>
    <li>Valor 1: Tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST > 0,05 mV)</li>
    <li>Valor 2: Mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes.</li>
  </ul>
<li><b>thalach:</b> Frecuencia cardíaca máxima alcanzada.</li>
<li><b>exang:</b> Angina inducida por el ejercicio</li>
  <ul>
    <li>Valor 1: Si</li>
    <li>Valor 0: No</li>
  </ul>
<li><b>old peak:</b> Depresión del ST inducida por el ejercicio en relación con el reposo.</li>
<li><b>slp:</b> La pendiente del segmento ST de ejercicio máximo (El segmento ST representa el período isoeléctrico cuando los ventrículos se encuentran entre la despolarización y la repolarización (https://es.wikipedia.org/wiki/Segmento_ST)).</li>
  <ul>
    <li>Valor 0: Pendiente abajo</li>
    <li>Valor 1: Plana</li>
    <li>Valor 2: Pendiente arriba</li>
  </ul>
<li><b>caa:</b> Número de vasos principales (0-3) coloreados por fluoroscopia</li>
<li><b>thall:</b> thalassemia (Resultado de la prueba de esfuerzo con talio)</li>
  <ul>
    <li>Valor 0: null</li>
    <li>Valor 1: Defecto fijo</li>
    <li>Valor 2: Normal</li>
    <li>Valor 3: Defecto reversible</li>
  </ul>
<li><b>output:</b> Diagnóstico de enfermedad cardíaca (estado de enfermedad angiográfico). Si el valor es 1 entonces el paciente es más propenso a tener una enfermedad cardíaca mientras que si es 0 entonces la situación del paciente no es crítica. El estrechamiento del vaso es peligroso ya que es posible que la sangre no bombee a través del corazón, lo que puede provocar un paro cardíaco.</li>
  <ul>
    <li>Valor 0: < 50% estrechamiento del diámetro. Menos posibilidades de ataque al corazón.</li>
    <li>Valor 1: > 50% estrechamiento del diámetro. Más posibilidades de ataque al corazón.</li>
  </ul>
</ul>  


## Integración y selección de los datos de interés a analizar. Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos originales, en base al objetivo que se quiera conseguir.  
```{r}
# Carga del fichero de datos y lectura de los mismos
dt_heart <- read.csv("heart.csv", header = TRUE)
```

```{r}
# Visualización previa de los datos.
# Tipo de dato asignado a cada campo para hacernos una idea del conjunto.
str(dt_heart)
sapply(dt_heart, function(x) class(x))
summary(dt_heart)
typeof(dt_heart)
```

```{r}
#install.packages("ggplot2")
library(purrr)
library(tidyr)
library(ggplot2)
```

```{r}
# Se realiza un estudio visual de todas las variables para analizar sus distribuciones así como posibles interpretaciones iniciales.
dt_heart %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    labs(x="Variables",y= "Frecuencia")  +
    geom_histogram()
```

En base a los resultados obtenidos, del conjunto de datos, podemos obtener una relación de primeras ideas como: 
<ul>
  <li>La asignación automática de tipo de datos de R al conjunto se basa en valores enteros y numéricos.</li>
  <li>Los pacientes de estudio se sitúan en edades comprendidas entre los 29 y los 77 años diendo la media de 54 años.</li>
  <li>Existe más cantidad de personas con sexo masculino que con femenino.</li>
  <li>Una minoría de las personas de estudio presenta dolor no-anginoso frente a la mayoría que son asintomáticos.</li>
  <li>La presión sistólica de los pacientes se centra en torno a los 130mm Hg.</li>
  <li>La distribución de los datos de la variable colesterol presenta cierta cola a la derecha por lo que los datos se concentrando en torno a los 250 mg/dl.</li>
  <li>La mayoría de los pacientes no presenta glucemia en ayunas por encima de los 120 mg/dl</li>
  <li>La mayoría de los pacientes no presenta angina inducida por el ejercicio</li>
</ul>

## Limpieza de los datos.
### ¿Los datos contienen ceros o elementos vacíos? Gestiona cada uno de estos casos.  
```{r}
# Verificar que no existen elementos NA.
sapply(dt_heart, function(x) sum(is.na(x)))
```

```{r}
# Verificar en base a la descripción de los atributos los valores distintos de cada uno de ellos para detectar aquellos que sean neesarios tratar.
sapply(dt_heart, function(x) unique(x))
```

<b>Como se aprecia en los resultados obtenidos será necesario tratar el atributo:</b>
<ul>
  <li><b>thall:</b> ya que en un apartado anterior, en el que se describe el dataset, se ha puntualizado que existen valores 0 que hacen referencia a un valor "null" y en concreto son dos observaciones. Por tanto, para dar sentido a estos valores se usará un método de imputación de valores basado en la similitud o diferencia entre los registros. Se usará kNN imputation ya que damos por hecho que los registros están relacionados. Igualmente siempre será mejor tratar los resultados de análisis de datos cercanos frente a datos vacíos.</li>
  <li><b>caa: se aprecia un valor fuera del rango definido. Dicho valor es el 4 que se tratará como un NA y se procederá de la misma manera que para el atributo anterior.</b></li>
</ul>

```{r}
suppressWarnings(suppressMessages(library(VIM)))
dt_heart$thall[dt_heart$thall == 0] <- NA # Sustituir valor 0(null) por NA
dt_heart$caa[dt_heart$caa == 4] <- NA # Sustituir valor 0(null) por NA
dt_heart$thall <- kNN(dt_heart)$thall
dt_heart$caa <- kNN(dt_heart)$caa
unique(dt_heart$thall)
unique(dt_heart$caa)
```
### Identifica y gestiona los valores extremos.  
Para poder visualizar de una manera rápida y sencilla para el humano realizamos un boxplot o gráfico de caja.
```{r}
boxplot(dt_heart)
```
```{r}
print("Val. extr. trtbps")
boxplot.stats(dt_heart$trtbps)$out
print("Val. extr. chol")
boxplot.stats(dt_heart$chol)$out
print("Val. extr. thalach")
boxplot.stats(dt_heart$thalach)$out
print("Val. extr. oldpeak")
boxplot.stats(dt_heart$oldpeak)$out
print("Val. extr. caa")
boxplot.stats(dt_heart$caa)$out
```
En base a los resultados del gráfico se identifican los siguientes atributos con posibles valores extremos:
<ul>
<li>trtbps</li>
<li>chol</li>
<li>thalach</li>
<li>exang</li>
<li>oldpeak</li>
<li>caa</li>
</ul>

Para el análisis de estudio no se tratarán estos valores como extremos ya que a pesar de ser cierto que se alejan de la media, son valores que se consideran reales y deben ser tratados en el estudio. Eliminarlos provocaría distorsión en la interpretación de los resultados.

## Análisis de los datos.  

### Selección de los grupos de datos que se quieren analizar/comparar (p.ej., si se van a comparar grupos de datos, ¿cuáles son estos grupos y qué tipo de análisis se van a aplicar?)  
Atendiendo a la definición, expuesta en el primer apartado, de cada variables del conjunto de datos, los agruparemos de la siguiente manera: 
<ul>
  <li>Grupo 1: Con el fin de estudiar el impacto de la glucemia en ayunas se seleccionarán aquellos datos cuyos pacientes presenten un nivel de Glucemia porencima de 120 mg/dl. La finalidad de esta prueba estadística es realizar un contraste de hipótesis para averiguar si los índices de Glucecia indican más inclinación a la enfermedad cardíaca. Esta variable nos permitirá identificar pacientes propensos a la enfermedad con valores de un indicador "pre-enfermedad cardíaca", es decir, podremos obtener resultados de un indicador sin que el paciente, posiblemente, haya sufrido una enfermedad cardíaca aún. De ahí la importancia de estudiar esta variable y su posible predicción. </li>
  <li>Grupo 2: Con el fin de estudiar el impacto de la pendiente del segmento ST de ejercicio máximo se seleccionarán aquellos datos cuyos pacientes presenten una pendiente abajo. La finalidad de esta prueba estadística es realizar un </li>
</ul>

Indistintamente de la creación de los grupos será muy interesante realizar un análisis de la correlación entre las variables del conjunto de datos para poder obtener más información sobre su comportamiento.
```{r}
# Grupo1
dt_heart_glucemia <- dt_heart[dt_heart$fbs == 1, ] 
str(dt_heart_glucemia)
```


### Comprobación de la normalidad y homogeneidad de la varianza.  
Para comprobar la normalidad de los distintos atributos que conforman el dataset se analizará una por una, con el fin de aplicar el estudio a aquellas que presenten normalidad. 
Se aplicarán distintas pruebas de normalidad sobre los datos siendo éstas: 
<ul>
  <li>Anderson-Darling: Estudio de bondad de ajuste que mide el área entre la línea ajustada y la función de distribución empírica.</li>
  <li>Lilliefors: Es una mejora de la prueba de Kolomogorov-Smirnov y se recomienda usar en conjunto de datos de más de 50 observaciones.</li>
</ul>
```{r}
# Identificar normalidad en variables del Dataset
library(nortest)
alpha = 0.05
col.names = colnames(dt_heart)
for (i in 1:ncol(dt_heart)) {
  if (i == 1) cat("Variables que no siguen una distribución normal mediante la 'Prueba de Anderson-Darling':\n")
  if (is.integer(dt_heart[,i]) | is.numeric(dt_heart[,i])) {
    p_val = ad.test(dt_heart[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i])
      # Format output
      if ( (i < ncol(dt_heart) - 1) | (i == ncol(dt_heart)-1) ) cat(", ") 
      if (i %% 5 == 0) cat("\n")
    }
  }
}
```
```{r}
library(nortest)
alpha = 0.05
col.names = colnames(dt_heart)
for (i in 1:ncol(dt_heart)) {
  if (i == 1) cat("Variables que no siguen una distribución normal mediante la 'Prueba de Lilliefors ':\n")
  if (is.integer(dt_heart[,i]) | is.numeric(dt_heart[,i])) {
    p_val = lillie.test(dt_heart[,i])$p.value 
    if (p_val < alpha) {
      cat(col.names[i])
      # Format output
      if ( (i < ncol(dt_heart) - 1) | (i == ncol(dt_heart)-1) ) cat(", ") 
      if (i %% 5 == 0) cat("\n")
    }
  }
}
```
Si nos apoyamos tanto en las gráficas de las variables mostradas en un apartado anterior y en la evaluación de los resultados de las pruebas de Anderson-Darling y Lilliefors (para un nivel de significación de 0.05 se ha obtenido p-values inferioriores) podemos afirmar la ausencia de normalidad en los datos de estudio.  Definir la ausencia o no, de normalidad es básico para las futuras pruebas estadísticas o modelos de regresión. 

A continuación, dado que no se cumple la condición de normalidad en los datos, estudiamos la homogeneidad de varianzas mediante la aplicación de un test de Fligner-Killeen. En este caso, estudiaremos esta homogeneidad en cuanto al grupo conformado por personas con glucemia en ayunas mayor que 120 mg/dl frente a personas con glucemia en ayunas menor que 120mg/dl. En el siguiente test, la hipótesis nula consiste en que ambas varianzas son iguales.

```{r}
fligner.test(output ~ fbs, data = dt_heart)
```
Puesto que obtenemos un p-valor superior a 0'05, aceptamos la hipótesis de que las varianzas de ambas muestras son homogéneas.

### Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.  

<b>¿Qué variables tienen mayor influencia para determinar la presencia de enfermedad cardíaca?</b>

Vamos a realizar un análisis de correlación entre las distintas variables para determinar cuáles de ellas ejercen una mayor influencia sobre la posible presencia de ataque cardíaco. En este caso, dado que los datos no siguen una distribución normal, utilizaremos el coeficiente de correlación de Spearman.
```{r}
corr_matrix <- matrix(nc = 2, nr = 0)
colnames(corr_matrix) <- c("estimate", "p-value")

# Calcular el coeficiente de correlación para cada variable
# con respecto al campo "output"
for (i in 1:(ncol(dt_heart) - 1)) {
  
    spearman_test = cor.test(dt_heart[,i],
                             dt_heart[,length(dt_heart)],
                             method = "spearman", exact = FALSE)
    corr_coef = spearman_test$estimate
    p_val = spearman_test$p.value
    # Add row to matrix
    pair = matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(dt_heart)[i]
}
print(corr_matrix)
```
Así, identificamos cuáles son las variables más correlacionadas con un diagnóstico de enfermedad cardíaca en función de su proximidad con los valores -1 y +1. Teniendo esto en cuenta, queda patente cómo la variable más relevante en el diagnóstico de enfermedad cardíaca es el número de vasos sanguíneos principales coloreados por fluoroscopia (caa), que está correlacionada negativamente con la variable objetivo, seguida del tipo de dolor en el pecho (cp) correlacionada positivamente, la presencia de angina inducida por el ejercicio (exng) correlacionada negativamente,
la frecuencia cardíaca máxima alcanzada (thalachh) correlacionada positivamente, y en último lugar la depresión del ST inducida por el ejercicio en relación con el reposo (oldpeak), correlacionada negativamente con la variable objetivo.

<b>¿Es propenso el paciente a tener una enfermedad cardíaca si la glucemia en ayunas es > 120 mg/dl?</b>

La segunda prueba estadística que se aplicará consistirá en un contraste de hipótesis para comprobar si existen diferencias significativas en la variable objetivo (output) entre los grupos definidos por la variable Glucemia en ayunas > 120 mg/dl (fbs), con el fin de  averiguar si el paciente es más o menos propenso a la presencia de enfermedad cardíaca según su nivel de glucemia en ayunas.
Como ambas variables son categóricas y los datos no cumplen la condición de normalidad, lo más eficiente es aplicar el test Chi-cuadrado de Pearson para comprobar si existen diferencias significativas entre ambas variables. Así, se plantea el siguiente contraste de hipótesis sobre la independencia de la propensión a tener un ataque cardíaco sobre el índice de glucemia en ayunas:
<ul>
  <li>H0 : La probabilidad de sufrir un ataque cardíaco es independiente de los niveles de glucemia en ayunas</li>
  <li>H1 : La probabilidad de sufrir un ataque cardíaco no es independiente de los niveles de glucemia en ayunas</li>
</ul>

```{r}
# Tabla de contingencia
heart_output_fbs <- table(dt_heart$output, dt_heart$fbs)
# Test Chi-cuadrado de independencia entre output y fbs
chisq.test(heart_output_fbs, correct = FALSE)
```
A partir de las frecuencias de cada valor del estado de enfermedad angiográfico para cada uno de los grupos, se observa que obtenemos un p-valor mayor que el valor de significación (0,05), por tanto no se rechaza la hipótesis nula. Así, no tenemos suficientes pruebas para concluir que si la glucemia del paciente en ayunas es > 120 mg/dl, el paciente sea propenso a poseer una enfermedad cardíaca.

<b>¿Es propenso el paciente a tener una enfermedad cardíaca si la pendiente del segmento ST de ejercicio máximo es hacia arriba?</b>

Esta prueba consistirá en un contraste de hipótesis para comprobar si existen diferencias significativas en la variable objetivo entre los grupos definidos por la variable Pendiente del segmento ST de ejercicio máximo (slp), con el fin de  averiguar si el paciente es más o menos propenso a la presencia de enfermedad cardíaca según el valor de la pendiente del segmento ST.
Nos encontramos en las mismas condiciones que el caso anterior, así que plantearemos un contraste de hipótesis sobre la independencia de la propensión a tener un ataque cardíaco sobre la pendiente del segmento ST:
<ul>
  <li>H0 : La probabilidad de sufrir un ataque cardíaco es independiente del valor de la pendiente del segmento ST.</li>
  <li>H1 : La probabilidad de sufrir un ataque cardíaco no es independiente del valor de la pendiente del segmento ST.</li>
</ul>

```{r}
# Test Chi-cuadrado de independencia entre output y slp
heart_output_slp <- table(dt_heart$output, dt_heart$slp)
chisq.test(heart_output_slp, correct = FALSE)
```
En este caso, se observa que obtenemos un p-valor mucho menor que el valor de significación fijado, así que rechazamos la hipótesis nula. Por tanto, podemos concluir que, efectivamente, el paciente es más propenso a padecer un ataque cardíaco si la pendiente del segmento ST es hacia arriba.
## Modelo de regresión logística
Tal y como se planteó en los objetivos de la actividad, resultará de mucho interés poder realizar predicciones sobre las probabilidades del paciente a sufrir un ataque cardíaco dadas sus características. Así, se calculará un modelo de regresión logística utilizando regresores tanto cuantitativos como cualitativos con el que poder realizar las predicciones de las probabilidades.
Para obtener un modelo de regresión logística considerablemente eficiente, lo que haremos será obtener varios modelos de regresión utilizando las variables que estén más correlacionadas con la variable de salida, según los resultados obtenidos anteriormente. Así, de entre todos los modelos que tengamos, escogeremos el mejor utilizando como criterio aquel que presente un menor AIC.
```{r}
# Regresores cuantitativos con mayor coeficiente de correlación con respecto a la probabilidad de ataque cardíaco
#caa thalachh oldpeak 
#Regresores cualitativos
#cp exng thall slp
# Variable a predecir
#$output

#1-fold Train-Test Split
set.seed(4321)
indexes <- sample(1:nrow(dt_heart), floor(.7*nrow(dt_heart)))

dt_heart.train <- dt_heart[indexes,]
dt_heart.test <- dt_heart[-indexes,]

# Generación de varios modelos
modelo1 <- glm(formula = output ~ caa + thalachh + oldpeak + cp + exng, data = dt_heart.train, family=binomial(link="logit"))
modelo2 <- glm(formula = output ~ caa + thalachh + oldpeak + cp + exng + thall + slp, data = dt_heart.train, family=binomial(link="logit"))
modelo3 <- glm(formula = output ~ caa + cp + exng, data = dt_heart.train, family=binomial(link="logit"))
modelo4 <- glm(formula = output ~ caa + thalachh + oldpeak, data = dt_heart.train,  family=binomial(link="logit"))
```
En este caso, la bondad del modelo se evaluará mediante la medida AIC. Dado que esta medida tiene en cuenta tanto la bondad del ajuste (el error) como la complejidad del modelo, seleccionaremos aquel modelo que resulte en el menor AIC.
```{r}
#  AIC de cada modelo
summary(modelo1)$aic
summary(modelo2)$aic
summary(modelo3)$aic
summary(modelo4)$aic
```
Observamos que el mejor modelo es el segundo, ya que es el que posee menor AIC:
```{r}
summary(modelo2)
```
Con estos valores dibujamos la gráfica del modelo de regresión logística:
```{r fig.height = 2, fig.width = 4}
library(magrittr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE) 

dt_heart_2 <- dt_heart[-indexes,] %>% mutate(test = 0.755579 -1.017496*caa     
                               + 0.016295 * thalachh      
                               - 0.654002 * oldpeak     
                               + 0.558657 * cp
                       - 0.873063 * exng
                       - 1.139052 * thall
                       + 0.492043 * slp)
ggplot(dt_heart_2, aes(y = output, x= test)) +
            geom_point(mapping = aes(col=as.factor(output))) +
            geom_vline(xintercept=-0.5) +
            geom_smooth(method = "glm",
                            method.args = list(family = "binomial"), 
                            se = FALSE) +
            coord_flip() +
            labs( x = "Output value of test",
                  y = "Probability of Heart Disease",
                  col = "True value")
```
Ahora, utilizando este modelo, podemos realizar predicciones sobre la probabilidad de sufrir un ataque cardíaco. Realizamos predicciones sobre los conjuntos de entrenamiento y test, con el objetivo de calcular la precisión en cada uno: 
```{r}
#Importar libreria requerida
library(caret, warn.conflicts = FALSE)
# Prediccion sobre los conjuntos de train y test
dt_heart.train.predict<-predict(modelo2,dt_heart.train)
dt_heart.test.predict<-predict(modelo2,dt_heart.test)
#Train accuracy for model:
mean(as.numeric(dt_heart.train.predict>=0)==dt_heart.train$output)
#Test accuracy for model
mean(as.numeric(dt_heart.test.predict>=0)==dt_heart.test$output)
```
Una vez calculados los valores predichos, pintamos la matriz de confusión:
```{r fig.height = 2, fig.width = 4}
# Matriz de confusion
cm <- confusionMatrix(data=factor(dt_heart.test$output), reference=factor(as.numeric(dt_heart.test.predict>=0)), dnn = c("Reference", "Prediction"))

plt <- as.data.frame(cm$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#009194") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("1","0")) +
        scale_y_discrete(labels=c("0","1"))
```
Observando la matriz de confusión, vemos que el modelo predice correctamente 79 de los 91 diagnósticos de pacientes, de los cuales 45 son clasificados correctamente como propensos a sufrir un ataque al corazón y 34 poseen una situación no crítica. Además, 10 pacientes son clasificados incorrectamente como poco propensos a enfermedad cardíaca y 2 pacientes son clasificados como propensos a la enfermedad, cuando en realidad no lo son.

Observamos también las medidas de bondad del modelo:
```{r}
confusionMatrix(data=factor(dt_heart.test$output), reference=factor(as.numeric(dt_heart.test.predict>=0)), dnn = c("Reference", "Prediction"))
```  
En este caso, podríamos decir que el modelo funciona bastante bien, puesto que tanto la sensibilidad como la especificidad son altas. Una prueba altamente sensible significa que hay pocos resultados falsos negativos y, por lo tanto, se pasan por alto menos casos propensos a la enfermedad. La especificidad de una prueba es su capacidad para designar como negativo a un individuo que no es propenso a una enfermedad. Una prueba altamente específica significa que hay pocos resultados falsos positivos.
## Representación de los resultados a partir de tablas y gráficas. Este apartado se puede responder a lo largo de la práctica, sin necesidad de concentrar todas las representaciones en este punto de la práctica.
A lo largo de la práctica, se ha realizado una exploración visual de las distintas variables y representaciones para analizar los valores extremos o vacíos. En el apartado 4 hemos visto que nuestros datos no cumplen la condición de normalidad. Para representar la normalidad de los datos se pueden utilizar los QQplots ya que permiten observar la similitud entre las distribuciones de dos conjuntos de datos, la analizada y una distribución normal ideal. Así, realizamos una representación de cada variable del dataset:
```{r}
par(mfrow=c(2,4))
qqnorm(dt_heart$age)
qqline(dt_heart$age,col=2)
qqnorm(dt_heart$sex)
qqline(dt_heart$sex,col=2)
qqnorm(dt_heart$cp)
qqline(dt_heart$cp,col=2)
qqnorm(dt_heart$trtbps)
qqline(dt_heart$trtbps,col=2)
qqnorm(dt_heart$chol)
qqline(dt_heart$chol,col=2)
qqnorm(dt_heart$fbs)
qqline(dt_heart$fbs,col=2)
qqnorm(dt_heart$restecg)
qqline(dt_heart$restecg,col=2)
qqnorm(dt_heart$thalachh)
qqline(dt_heart$thalachh,col=2)
qqnorm(dt_heart$exng)
qqline(dt_heart$exng,col=2)
qqnorm(dt_heart$oldpeak)
qqline(dt_heart$oldpeak,col=2)
qqnorm(dt_heart$slp)
qqline(dt_heart$slp,col=2)
qqnorm(dt_heart$caa)
qqline(dt_heart$caa,col=2)
qqnorm(dt_heart$thall)
qqline(dt_heart$thall,col=2)
qqnorm(dt_heart$output)
qqline(dt_heart$output,col=2)
```
Como podemos observar, todas las distribuciones se alejan mucho de la normal.

Por otra parte, representaremos una matriz de correlación para visualizar la correlación entre las variables:
```{r fig.height = 3, fig.width = 5}
# Cargamos librería
library(corrplot)
# Pintamos la el gráfico
corrplot(cor(dt_heart), is.cor = FALSE)
```
En este gráfico podemos observar como efectivamente, las variables más correlacionadas con nuestra variable objetivo son: caa, thalach, oldpeak, cp, exng, thall y slp, ya que son las que tienen un mayor y más marcado círculo.
En cuanto a los contrastes de hipótesis, las diferencias encontradas entre los grupos se pueden analizar a través de diagramas de barras, para ver más claramente la dirección de estas diferencias. Así, en este caso se puede observar que no se aprecian grandes diferencias cuando la glucemia en ayunas es mayor que 120 mg/dl, ya que la frecuencia es similar para propensos a ataque cardíaco y para situaciones no críticas.
```{r fig.height = 2, fig.width = 4}
# Convertir variables a factor
dt_heart$fbs <- as.factor(dt_heart$fbs)
dt_heart$output <- as.factor(dt_heart$output)
# Reprentacion gráfica
ggplot(data = dt_heart, aes(x = fbs, fill = output)) + geom_bar()
```
Por otro lado,se aprecia una mayor frecuencia a que el diagnóstico sea enfermedad cardíaca si la pendiente del segmento ST de ejercicio máximo es hacia arriba, como podemos observar en el diagrama:
```{r fig.height = 2, fig.width = 4}
# Convertir variables a factor
dt_heart$fbs <- as.factor(dt_heart$slp)
dt_heart$output <- as.factor(dt_heart$output)
# Reprentacion gráfica
ggplot(data = dt_heart, aes(x = slp, fill = output)) + geom_bar()
```
En el caso de la regresión/clasificación logística, nuevamente se ha optado por realizar la representación del modelo de regresión logística y la matriz de confusión en el propio apartado.
```{r}
# Exportar el fichero resultante con los datos finales analizados
write.csv(dt_heart, "heart_final.csv", row.names=FALSE)
```

## Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?
En primer lugar, se ha realizado una exploración visual para comprobar la distribución de los datos y se han tratado valores nulos en las variables. Los valores outliers no se han tratado como tal, ya que son valores reales y su supresión llevaría a una interpretación errónea.
De los métodos de contraste de pótesis y correlaciones, se puede observar que los pacientes con la pendiente del segmento ST de ejercicio máximo hacia arriba son más propensos a padecer un ataque cardíaco. Además, se ha verificado que la glucemia en ayunas > 120 mg/dl no es un factor significativo a la hora de diagnosticar la propensión a esta enfermedad. Se ha confirmado que la variable más significativa a la hora de detectar un posible ataque cardíaco es el número de vasos sanguíneos coloreados por fluoroscopia (caa), ya que en este caso se puede detectar una posible obstrucción en algún tejido que no sea coloreado. Algunas de las variables cuantitativas cuyos valores pueden ser indicativo de aumentar/reducir la probabilidad a padecer la enfermedad son la frecuencia cardíaca máxima alacanzada (thalachh), la depresión del ST inducida por el ejercicio en relación con el reposo (oldpeak). En cuanto a las variables categóricas, cobran importancia el tipo de dolor en el pecho (cp), la presencia de angian inducida por el ejercicio (exng), el resultado de la prueba de esfuerzo con talio (thall) y la pendiente del segmento ST de ejercicio máximo (slp). Posteriormente, con estas variables se han entrenado varios modelos de regresión logística, eligiendo finalmente el de mayor bondad, y realizando predicciones sobre el conjunto de test. El modelo funciona bastante bien, puesto que tanto la sensibilidad como la especificidad son altas, y posee una precisión de 0.8681. Es decir, la probabilidad de que el modelo clasifique correctamente a una persona propensa a padecer un ataque cardíaco es de +-87%.
```{r}
library(knitr)
df <- data.frame(Contribuciones = c("Investigación previa","Redacción de las respuestas","Desarrollo del código","Participación en el vídeo"),
                 Firma = c("Alba Caderno Fernández, Diego García García","Alba Caderno Fernández, Diego García García","Alba Caderno Fernández, Diego García García","Alba Caderno Fernández, Diego García García"))
kable(df)
```
